# SVHN-YoloV4
NCTU VRDL HW2
## Hardware
The following specs were used to create the original solution.
* Ubuntu 16.04 LTS
* Intel(R) Core(TM) i7-6700 CPU @ 3.40GHz
* NVIDIA TitanX
## Dataset
Street View House Numbers

SVHN dataset contains 33,402 trianing images, 13,068 test images.
## Requirements
For training:

Reference: https://github.com/AlexeyAB/darknet.

For speed benchmark:
* numpy		1.18.5
* tensorflow		2.3.0
* opencv		4.4.0
* gputil	1.4.0
## Data preprocessing
* Convert the annotation to Yolo format. We can find the VOC format annotation of SVHN dataset on: https://github.com/penny4860/svhn-voc-annotation-format. It's easier to convert the VOC format to Yolo format. The format of each bounding box should be: [class x_center y_center width height].
* Yolo can’t train without label 0, so the training label should be 0 to 9 instead of 1 to 10. 
* The annotations should be in the same folder with train images / test images.
## Training
I use the YoloV4 model in: https://github.com/AlexeyAB/darknet. You can find more training details in it.
1.	Make file settings:
Modify the Makefile and set GPU=1, CUDNN=1, opencv=1.
2.	.names file:
Create file svhn.names in the directory build\darknet\x64\data\, with objects names - each in new line
3.	.data file:
Create file svhn.data in the directory build\darknet\x64\data\, containing:
* classes = 10
* train = path to ‘train.txt’ which contains all of the path of training images.
* valid = path to ‘test.txt’ which contains all of the path of validation images.
* names = path to ‘svhn.names’
* backup = path you want to save the weights
4.	.cfg file:
Create file yolov4-svhn.cfg with the same content as in yolov4-custom.cfg (or copy yolov4-custom.cfg to yolov4-svhn.cfg) and: 
*	change line max_batches to 20000 (classes*2000)
*	change line steps to 80% and 90% of max_batches. In this case, steps=16000,18000
*	set network size width=416, height=416 or any value multiple of 32, I tested 416x416 and 512x256, the best input size is 416x416
*	change line classes=80 to classes=10.
*	change [filters=255] to filters=(classes + 5)x3 in the 3 [convolutional] before each [yolo] layer, keep in mind that it only has to be the last [convolutional] before each of the [yolo] layers. In this case filters=45
*	If the input size is 512x256, change the anchor values in each [yolo] layer to: 29, 67, 37,112, 57, 112, 46, 166, 64, 150, 66, 195, 85, 166, 90, 205, 121, 204. The best anchor values can be generated by using command: ./darknet detector calc_anchors data/svhn.data -num_of_clusters 9 -width 512 -height 256 -show.
*	Change line mosaic=1 to mosaic=0.
*	And line flip=0. No augmentation method in this task will be better.

In this part, I used pretrained weight yolov4.conv.174 to get better result.

Training command: 
./darknet detector train data/svhn.data cfg/yolov4-svhn.cfg yolov4.conv.174
## Testing and output .json file
* Testing a single image: 

./darknet detector test data/svhn.data cfg/yolov4-svhn.cfg backup/yolov4-svhn_final.weights data/test/1.png

* Output .json file:

./darknet detector test data/svhn.data cfg/yolov4-svhn.cfg backup/yolov4-svhn_final.weights -ext_output -dont_show -out result.json < data/test.txt

It will out put a 'result.json' file, put it in the same directory with 'json-output.py', and execute 'json-output.py'.

The highest mAP I got is: 0.45704
## Speed bench mark
I tested the weight on Google Colab. The speed testing code reference is from: https://github.com/StephenEkaputra/SVHN-YOLOV3-CUSTOM.

The method I used to test the speed is cv2.dnn.readNetFromDarknet. But the old version of opencv doesn’t support YoloV4, so the version of opencv needs to be at least 4.4.0.

The GPU in my Google Colab is Tesla P4.

The best speed per image I got is 27.6 ms.
## References
1.	SVHN VOC annotation format:
https://github.com/penny4860/svhn-voc-annotation-format.
2.	AlexeyAB darknet:
https://github.com/AlexeyAB/darknet.
3.	SVHN-YOLOV3-CUSTOM:
https://github.com/StephenEkaputra/SVHN-YOLOV3-CUSTOM.
